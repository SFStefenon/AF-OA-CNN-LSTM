# Scalable filtered attention CNN-LSTM optimized model

This repository presents an attention-based CNN-LSTM model optimized by an adaptive tree-structured Parzen estimator (ATPE) with a scalable filtered input stage.
The proposed algorithm considers an evaluation of random search, annealing search, TPE, and ATPE to model hyperparameter tuning.

The model is compared to TiDE, NHITS, N-BEATS, NBEATSx, DilatedRNN, LSTM, GRU, DeepAR, TFT, Informer, PatchTST, FEDformer, TCN, BiTCN, TimesNet deep learning structures. 
The complete pipeline of the analysis of proposed method is presented below:

![Kin-Project](https://github.com/user-attachments/assets/dcdf6038-88ef-48ba-8b7f-ca8a73881e3c)
